{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0297e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os \n",
    "import pickle \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime \n",
    "from pathlib import Path \n",
    "\n",
    "from sklearn.model_selection import train_test_split , RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor , GradientBoostingRegressor , HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge \n",
    "# from sklearn.pipeline import Pipeline \n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error,r2_score\n",
    "\n",
    "import mlflow \n",
    "import mlflow.sklearn \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de18488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'xgboost'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except Exception as e:\n",
    "    HAS_XGB = False\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55057857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 23:14:16 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/12 23:14:16 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/12 23:14:16 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/12 23:14:16 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/12 23:14:16 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/12 23:14:16 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///d:/Deep Learning Projects/travel-mlops-capstone/mlruns/1', creation_time=1765450009537, experiment_id='1', last_update_time=1765450009537, lifecycle_stage='active', name='flight_price_baseline', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths Configurations \n",
    "\n",
    "data_path = Path('data/flights_cleaned.npz')\n",
    "\n",
    "artifacts_dir = Path('artifacts')\n",
    "\n",
    "mlflow_experiment_name = 'flight_price_baseline'\n",
    "random_state = 42 \n",
    "\n",
    "mlflow.set_experiment(mlflow_experiment_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2efac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (271888, 28)\n",
      "Y shape : (271888,)\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "\n",
    "assert data_path.exists(),f\"{data_path} not found\"\n",
    "npz = np.load(data_path , allow_pickle = True)\n",
    "if \"X\" in npz.files and 'y' in npz.files:\n",
    "    X = npz[\"X\"]\n",
    "    y = npz['y']\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Could not find X and y arrays inside flights_cleaned.npz\")\n",
    "\n",
    "print(\"X shape :\", X.shape )\n",
    "print(\"Y shape :\",y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6695ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (244699, 28) (244699,)\n",
      "Test shapes : (27189, 28) (27189,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split \n",
    "\n",
    "xtrain , xtest , ytrain , ytest = train_test_split(X , y , test_size = 0.1 , random_state= random_state)\n",
    "\n",
    "print('Train shapes:', xtrain.shape, ytrain.shape)\n",
    "print('Test shapes :', xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982b7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9869d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_log(model_name , model , xtrain , ytrain , xtest , ytest , param_search = None , n_iter = 20):\n",
    "\n",
    "    \"\"\"\n",
    "    Train(with optional RandomizedSearchCV) and log everything MLFLOW\n",
    "\n",
    "    Returns : best_estimator , dict(metrics) \n",
    "    \n",
    "   \n",
    "    \"\"\"\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    with mlflow.start_run(run_name = run_name):\n",
    "        mlflow.set_tag('model_type' , model_name)\n",
    "\n",
    "        # If param_search provided ,run RandomizedSearchCV \n",
    "\n",
    "        if param_search:\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator = clone(model),\n",
    "                param_distributions=param_search,\n",
    "                n_iter = min(n_iter , 40),\n",
    "                cv = 3,\n",
    "                scoring = 'neg_mean_squared_error',\n",
    "                random_state = random_state,\n",
    "                n_jobs = -1,\n",
    "                verbose = 0\n",
    "            )\n",
    "\n",
    "            search.fit(xtrain , ytrain)\n",
    "            best = search.best_estimator_\n",
    "            best_params = search.best_params_\n",
    "            mlflow.log_params({f\"best_{k}\": v for k , v in best_params.items()})\n",
    "\n",
    "            # log CV results\n",
    "\n",
    "            try:\n",
    "                cvres = pd.DataFrame(search.cv_results_)\n",
    "                cv_summary = cvres[['params','mean_test_score','std_test_score','rank_test_score']].to_dict(orient = 'records')\n",
    "\n",
    "                mlflow.log_text(json.dumps(cv_summary , default = str),'cv_summary.json')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "            best = clone(model)\n",
    "            best.fit(xtrain , ytrain)\n",
    "            mlflow.log_params({'note':'no-hyperparam-search'})\n",
    "        \n",
    "\n",
    "        # predict and metrics\n",
    "\n",
    "        preds = best.predict(xtest)\n",
    "        rmse = mean_squared_error(ytest , preds , squared=False)\n",
    "        mae = mean_absolute_error(ytest , preds) \n",
    "        r2 = r2_score(ytest , preds)\n",
    "\n",
    "        mlflow.log_metric('rmse', float(rmse))\n",
    "        mlflow.log_metric('mae', float(mae))\n",
    "        mlflow.log_metric('r2', float(r2))\n",
    "\n",
    "        # log the model via mlflow.sklearn\n",
    "\n",
    "        mlflow.sklearn.log_model(best , artifact_path = 'model' )\n",
    "\n",
    "        # save and log a pickle locally as well\n",
    "\n",
    "        model_file = artifacts_dir/f'{model_name}_best.pkl'\n",
    "        with open(model_file , 'wb') as f:\n",
    "            pickle.dump(best , f)\n",
    "\n",
    "        mlflow.log_artifact(str(model_file) , artifact_path='model_files')\n",
    "\n",
    "        # if model has feature_importances_ , log top features \n",
    "\n",
    "        try:\n",
    "            importances = getattr(best , 'feature_importances_',None)\n",
    "            if importances is not None:\n",
    "                imp_df = pd.DataFrame({'feature_idx':list(range(len(importances))),\n",
    "                                       'importance' : importances\n",
    "                                       })\n",
    "                \n",
    "                imp_csv = artifacts_dir/f'{model_name}_feature_importances.csv'\n",
    "                imp_df.to_csv(imp_csv , index = False)\n",
    "\n",
    "                mlflow.log_artifacts(str(imp_csv) , artifacts_path = 'feature_importances')\n",
    "\n",
    "        except Exception :\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"{model_name} done - RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "        return best , {'rmse':rmse , 'mae':mae  , 'r2':r2}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5289257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost not found — skipping xgboost. To enable, install xgboost in the kernel\n"
     ]
    }
   ],
   "source": [
    "# Defining models and search spaces \n",
    "\n",
    "models_and_search = []\n",
    "\n",
    "# 1) Random Forest \n",
    "\n",
    "rf = RandomForestRegressor(random_state = random_state)\n",
    "rf_search = {\n",
    "    'n_estimators' : [100 , 200 , 400],\n",
    "    'max_depth' : [6, 10, 20 , None],\n",
    "    'min_samples_leaf' : [1,2,4]\n",
    "}\n",
    "\n",
    "models_and_search.append(('random_forest' , rf , rf_search))\n",
    "\n",
    "# 2) Gradient Boosting (sklearn)\n",
    "gb = GradientBoostingRegressor(random_state=random_state)\n",
    "gb_search = {\n",
    "'n_estimators': [100, 200, 400],\n",
    "'learning_rate': [0.01, 0.05, 0.1],\n",
    "'max_depth': [3, 5, 8]\n",
    "}\n",
    "models_and_search.append(('grad_boost', gb, gb_search))\n",
    "\n",
    "\n",
    "# 3) HistGradientBoosting (fast, sklearn >=0.21)\n",
    "hgb = HistGradientBoostingRegressor(random_state=random_state)\n",
    "hgb_search = {\n",
    "'max_iter': [100, 200, 400],\n",
    "'learning_rate': [0.01, 0.05, 0.1],\n",
    "'max_depth': [3, 6, 12]\n",
    "}\n",
    "models_and_search.append(('hist_gb', hgb, hgb_search))\n",
    "\n",
    "# 4) XGBoost (if available)\n",
    "if HAS_XGB:\n",
    "    xgb = XGBRegressor(objective='reg:squarederror', random_state=random_state, n_jobs=-1)\n",
    "    xgb_search = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 6, 10]\n",
    "    }\n",
    "    models_and_search.append(('xgboost', xgb, xgb_search))\n",
    "else:\n",
    "    print('XGBoost not found — skipping xgboost. To enable, install xgboost in the kernel')\n",
    "\n",
    "\n",
    "# 5) Linear model (Ridge) as a simple baseline\n",
    "ridge = Ridge(random_state=random_state)\n",
    "ridge_search = {\n",
    "'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "models_and_search.append(('ridge', ridge, ridge_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732cc723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting: random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 23:58:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest done - RMSE: 0.5282, MAE: 0.0409, R2: 1.0000\n",
      "\n",
      "Starting: grad_boost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 01:00:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_boost done - RMSE: 0.2121, MAE: 0.1468, R2: 1.0000\n",
      "\n",
      "Starting: hist_gb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 01:03:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hist_gb done - RMSE: 3.6278, MAE: 2.6443, R2: 0.9999\n",
      "\n",
      "Starting: ridge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Deep Learning Projects\\travel-mlops-capstone\\travel_venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=20. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "2025/12/13 01:03:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge done - RMSE: 103.0210, MAE: 80.7872, R2: 0.9189\n",
      "\n",
      "All models trained. Summary:\n",
      "           model        rmse        mae        r2\n",
      "1     grad_boost    0.212119   0.146758  1.000000\n",
      "0  random_forest    0.528176   0.040939  0.999998\n",
      "2        hist_gb    3.627784   2.644270  0.999899\n",
      "3          ridge  103.021000  80.787184  0.918940\n"
     ]
    }
   ],
   "source": [
    "# Running training loop\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name , model , search_space in models_and_search:\n",
    "    print('\\nStarting:',name)\n",
    "    best_est , metrics = evaluate_and_log(\n",
    "        model_name = name ,\n",
    "        model = model , \n",
    "        xtrain=xtrain ,\n",
    "        ytrain = ytrain,\n",
    "        xtest = xtest , \n",
    "        ytest = ytest,\n",
    "        param_search = search_space,\n",
    "        n_iter = 20\n",
    "    )\n",
    "    results[name] = {'estimator':best_est , 'metrics':metrics}\n",
    "\n",
    "# save summary of results\n",
    "\n",
    "summary_df = pd.DataFrame([{\n",
    "    'model':k,\n",
    "    'rmse':v['metrics']['rmse'],\n",
    "    'mae':v['metrics']['mae'],\n",
    "    'r2':v['metrics']['r2']\n",
    "} for k , v in results.items()])\n",
    "\n",
    "summary_df = summary_df.sort_values('rmse')\n",
    "summary_df.to_csv(artifacts_dir/'model_comparison.csv' , index = False)\n",
    "\n",
    "mlflow.log_artifacts(str(artifacts_dir/'model_comparison.csv'))\n",
    "print('\\nAll models trained. Summary:')\n",
    "print(summary_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
